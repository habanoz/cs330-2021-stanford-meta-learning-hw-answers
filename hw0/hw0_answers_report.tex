\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
}


% \usepackage{fullpage}
% \usepackage{sectsty}
% \usepackage{xcolor}
% \usepackage{tgpagella}
% \usepackage{enumitem}

\sectionfont{\fontsize{15}{20}\selectfont}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\E}{\mathbb{E}}
\begin{document}

\begin{center}
{\Large \textbf{CS 330 Autumn 2022/2023 Warmup Homework 0} \\ Multitask Training for Recommender Systems
\\ Due Monday October 3, 11:59 PM PST}
\vspace{0.2cm}

\begin{tabular}{rl}
SUNet ID: &  \\
Name: & \\
Collaborators: & 
\end{tabular}
\end{center}

By turning in this assignment, I agree by the Stanford honor code and declare
that all of this is my own work.



\section{Overview}
In this assignment, we will implement a multi-task movie recommender system based on the classic Matrix Factorization \cite{Yehuda2009matrix} and Neural Collaborative Filtering ~\cite{he2017neural} algorithms. In particular, we will build a model based on the \href{https://www2.seas.gwu.edu/~simhaweb/champalg/cf/papers/KorenBellKor2009.pdf}{BellKor solution} to the Netflix Grand Prize challenge and extend it to predict both likely user-movie interactions and potential scores. In this assignment you will implement a multi-task neural network architecture and explore the effect of parameter sharing and loss weighting on model performance.

% \begin{enumerate}
%     \item Implement a multi-task neural network architecture and explore the effect of parameter sharing on model performance.
% \end{enumerate}
\vspace{0.2cm}
\noindent The main goal of these exercises is to familiarize yourself with multi-task architectures, the training pipeline, and coding in PyTorch. These skills will be important in the course. \textbf{Note: This assignment is a warmup, and is shorter than future homeworks will be.}

\vspace{0.2cm}

\noindent\textbf{Submission}: To submit your work, submit one pdf report and one zip file to GradeScope, where the report contains answers to the deliverables listed below and the zip file contains the code with your filled-in solutions. 

\vspace{0.2cm}

\noindent\textbf{Code Overview:} The code consists of several files; however, you will only need to interact with two:

\begin{itemize}
    \item \texttt{main.py}: To run experiments, execute this file by passing the corresponding parameters. 
    \item \texttt{models.py}: This file contains our multi-task prediction model \textbf{MultiTaskNet}, which you will need to finish implementing in PyTorch.
\end{itemize}


\section{Dataset and Evaluation}

\paragraph{Dataset.} In this assignment, we will use movie reviews from the \href{https://grouplens.org/datasets/movielens/100k}{MovieLense dataset}. The dataset consists of 100K reviews of 1700 movies generated by 1000 users. Although each user interaction contains several levels of meta-data, we'll only consider tuples of the type \textbf{(userID, itemID, rating)}, which contain an anonymized user ID, movie ID and the score assigned by the user to the movie from 1 to 5. We randomly split the dataset into a \textbf{train} dataset, which contains 95\% of all ratings, and a \textbf{test} dataset, which contains the remaining 5\%.

\paragraph{Problem Definition.}
Given the dataset defined above, we would like to train a model $f(\text{userID}, \text{itemID})$ that predicts: 1) the probability $p$ that the user would watch the movie and 2) the score $r$ they would assign to it from 1 to 5. For some intuition on this setting, consider a user who only watches comedy and action movies. It would not make sense to recommend them a horror movie since they don't watch those. At the same time, we would want to recommend comedy or action movies that the user is likely to score highly. 

\paragraph{Evaluation.}
Once we have our trained model, we evaluate it on the test set.

\vspace{0.2cm}
\noindent \emph{Score Prediction.} We will evaluate the mean-squared error of movie score prediction on the held-out user ratings, i.e.
    $
        \frac{1}{N}\sum_{i=1}^N ||\hat{r}_i-r_i||^2,
    $
    where $\hat{r}_i$ is the predicted score for user-movie pair $(\text{userID}_i,\text{itemID}_i)$. The summation is over all pairs in the test set. Better models achieve lower mean-squared errors.
    
    \vspace{0.2cm}
    \noindent \emph{Likelihood Prediction.}  
    % Our dataset contains ratings for movies the users have seen. 
    To evaluate the quality of the likelihood model, we use the \href{https://en.wikipedia.org/wiki/Mean_reciprocal_rank} {mean reciprocal rank metric}, which provides a higher score for highly ranking the movies the user has seen. The metric is computed as follows: 1) for each user, rank all movies based on the probability that the user would watch them; 2) remove movies we know the user has watched (those in the training set); 3) compute the average reciprocal ranking of movies the user has watched from the held-out set. 
    % In mathematical terms:
    % \begin{equation}
    %     \text{MRR} = \frac{1}{N_{\text{users}}}\sum_{i=1}^{N_{\text{users}}}\frac{1}{N_i}\sum_{j=1}^{N_i}\frac{1}{\text{rank}_{i,j}}
    % \end{equation}
    % where $N_{\text{users}}$ is the number of users in the dataset, $N_i$ is the number of held-out movies user $\text{userID}_i$ has seen and $\text{rank}_{i,j}$ is the rank of movie $\text{itemID}_j$ for user $\text{userID}_i$ given by our model. For example, consider the dataset in the following table:
    
    % \begin{center}
    % \begin{tabular}{|c c c c|} 
    %  \hline
    %  userID & Held-out  Movies & Model Ranking All& Mean Reciprocal Rank \\ [0.5ex] 
    %  \hline\hline
    %  1 & A, B & B, C, D, A, G & $\frac{1}{2}\Big[\frac{1}{4} + \frac{1}{1}\Big]$ \\ 
    %  \hline
    %  2 & B & A, B, C, G, D & $\frac{1}{1}\Big[\frac{1}{2}\Big]$ \\
    %  \hline
    %  3 & A, B, C & A, D, B, C, G & $\frac{1}{3}\Big[\frac{1}{1} + \frac{1}{3} + \frac{1}{4}\Big]$ \\
    %  \hline

    % \end{tabular}
    % \end{center}
    
    % \noindent The MRR for the batch is 0.55. Better models achiever higher MRR scores.
    
%\end{enumerate}


\section{Problems}

To install all required packages for this assignment you can run:

\texttt{pip install -r} \texttt{ requirements.txt}.


% \subsection{Problem 1: Implement Multi-Task Model}


\noindent In this problem, we will implement a multi-task model using Matrix Factorization \cite{Yehuda2009matrix} and regression-based modelling:

\vspace{0.2cm}

\noindent\textbf{Matrix Factorization}: Consider an interaction matrix $M$, where $M_{ij} = 1$ if $\text{userID}_i$ has rated movie with $\text{itemID}_j$ and $0$ otherwise. We will represent each user with a latent vector $\mathbf{u}_i\in\mathbb{R}^d$ and each item with a latent vector $\mathbf{q}_i\in\mathbb{R}^d$. We model the interaction probability $p_{ij}=\log P(M_{ij}=1)$ in the following way:
\begin{equation}
    p_{ij} = \mathbf{u}_i^T\mathbf{q}_j + a_i + b_j
    \label{eq:prob}
\end{equation}
where $a_i$ is a user-specific bias term and $b_j$ is a movie-specific bias term. At each training step we sample a batch of triples $(\text{userID}_i, \text{itemID}_j^+, \text{itemID}_{j'}^-)$ with size $B$, such that $M_{i, j} = 1$, while $\text{itemID}_{j'}^-$ is randomly sampled (indicating no user preference). Let
\begin{equation} 
\begin{split}
p^+_{ij} =  \mathbf{u}_i^T\mathbf{q}_j + a_i + b_j \\
p^-_{ij'} =  \mathbf{u}_i^T\mathbf{q}_{j'} + a_i + b_{j'}
\end{split}
\label{eq:p}
\end{equation}
and optimize the  Bayesian Personalised Ranking (BPR) \cite{Rendle2009BPR} pairwise loss function:
\begin{equation}
    \mathcal{L}_F(\mathbf{p}^+, \mathbf{p}^-)=\frac{1}{B}\sum_{i=1}^B 1-\sigma(p_{ij}^+-p_{ij'}^-)
    \label{eq:l1}
\end{equation}

\noindent where $\sigma$ is the sigmoid function.

\vspace{0.2cm}

\noindent\textbf{Regression Model}: For training the regression model, we consider only batches of tuples $(\text{userID}_i, \text{itemID}_j^+, r_{ij})$, such that $M_{i, j} = 1$ and $r_{ij}$ is the numerical rating $\text{userID}_i$ assigned to $\text{itemID}_j^+$. Using the same latent vector representations as before, we will concatenate $[\mathbf{u}_i, \mathbf{q}_j, \mathbf{u}_i * \mathbf{q}_j]$ (where $*$ denotes element-wise multiplication) together and pass it through a neural network with a single hidden layer:
\begin{equation}
    \hat{r}_{ij}=f_{\theta}([\mathbf{u}_i, \mathbf{q}_j, \mathbf{u}_i * \mathbf{q}_j])
    \label{eq:reg}
\end{equation}
We train the model using the mean-squared error loss:
    \begin{equation}
       \mathcal{L}_R(\mathbf{\hat{r}}, \mathbf{r})= \frac{1}{B}\sum_{i=1}^B ||\hat{r}_{ij}-r_{ij}||^2
     \label{eq:r}
    \end{equation}

\vspace{0.2cm}

\noindent \noindent\textbf{Your Implementation}: The first part of the assignment is to implement the above model in \texttt{models.py}. First you need to define each component when the model is initialized. 

\begin{enumerate}
    \item Consider the matrix $\mathbf{U} = [\mathbf{u}_1|,\ldots,|\mathbf{u}_{N_{\text{users}}}]\in\mathbb{R}^{N_{\text{users}}\times d}$, $\mathbf{Q} = [\mathbf{q}_1|,\ldots,|\mathbf{q}_{N_{\text{items}}}]\in\mathbb{R}^{N_{\text{items}}\times d}$, $\mathbf{A} = [a_1, \ldots, a_{N_{\text{users}}}]\in \mathbb{R}^{N_{\text{users}}\times 1}$, $\mathbf{B} = [b_1, \ldots, b_{N_{\text{items}}}]\in \mathbb{R}^{N_{\text{items}}\times 1}$. Implement $\mathbf{U}$ and $\mathbf{Q}$ as \texttt{ScaledEmbedding} layers  with parameter $d=\texttt{embedding\_dim}$ and $\mathbf{A}$ and $\mathbf{B}$ as \texttt{ZeroEmbedding} layers with parameter $d=1$ (defined in \texttt{models.py}). These are instances of \href{https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html}{PyTorch Embedding} layers with a different weight initialization, which facilitates better convergence.
    
    \item Next implement $f_{\theta}([\mathbf{u}_i, \mathbf{q}_j, \mathbf{u}_i * \mathbf{q}_j])$ as an MLP network. The class \texttt{MultiTaskNet} has \texttt{layer\_sizes} argument, which is a list of the input shapes of each dense layer. Notice that by default $\texttt{embedding\_dim}$=32, while the input size of the first layer is 96, since we concatenate $[\mathbf{u}_i, \mathbf{q}_j, \mathbf{u}_i * \mathbf{q}_j]$ before processing it through the network. Each layer (except the final layer) should be followed by a ReLU activation. The final layer should output the final user-item predicted score in and have an output size of 1.
    
    \item The \texttt{MultiTaskNet} class has an \texttt{embedding\_sharing} attribute. Implement your model in such a way that when  \texttt{embedding\_sharing=True} a single latent vector representation is used for both the factorization and regression tasks and vice versa. 
    
\end{enumerate}
    
\noindent In the second part of the problem you need to implement the \texttt{forward} method of the \texttt{MultitaskNet} module. The \texttt{forward} method receives a batch of $(\text{userID}_i, \text{itemID}_j)$ of user-item pairs. The model should output a probability $p_{ij}$ of shape $(batch\_size,)$ that user $i$ would watch movie $j$, given by Eq. \ref{eq:prob} and a predicted score $\hat{r}_{ij}$ of shape $(batch\_size,)$ the user $i$ would assign to movie $j$, given by Eq. \ref{eq:reg}. \textbf{Be careful with output tensor shapes!}




% \subsection{Problem 2: Debug Model Training}

% The main algorithm training loop is implemented in \texttt{multitask.py}. Given a batch of tuples $(\text{userID}_i, \text{itemID}_j^+, \text{itemID}_{j'}^-, r_{ij})$, such that $M_{i, j} = 1$ and $M_{i, j'}=0$, we user our model to predict $p_{ij}^+, p_{ij'}^-, \hat{r}_{ij}$ as defined in Eq. \ref{eq:p} and Eq. \ref{eq:r}. We optimize a weighted joint loss 
% \begin{equation}
%     \min_{\theta} \lambda_F \mathcal{L}_F(\mathbf{p}^+, \mathbf{p}^-)+ \lambda_R\mathcal{L}_R(\mathbf{\hat{r}}, \mathbf{r})
% \end{equation}

% \noindent where $\mathcal{L}_F$ is as defined in Eq. \ref{eq:l1} and $\mathcal{L}_R$ in Eq. \ref{eq:r}. We have introduced a deliberate bug in the loss function implementations in the \texttt{fit} method of \texttt{multitask.py}, which you have to debug. In your work, consider the model outputs and specific loss implementations above. It might be helpful to check the loss function implementations in \texttt{losses.py}, but you should not modify those.

\section{Write-up}
To execute experiments run the \texttt{main.py} script, which will automatically log training MSE loss, BPR loss and test set MSE loss and MRR scores to TensorBoard. Once you're done with your implementation run the following 4 experiments:

\begin{enumerate}
    \item Evaluate a model with shared representations and task weights $\lambda_F=0.99, \lambda_R=0.01$. You can run this experiment by running:
    
    \texttt{python main.py --factorization\_weight 0.99 --regression\_weight 0.01 \\--logdir run/shared=True\_LF=0.99\_LR=0.01}
    
    Here the \texttt{--factorization\_weight} and \texttt{--regression\_weight} arguments correspond to $\lambda_F$ and  $\lambda_R$ respectively.
    
    \item Evaluate a model with shared representations and task weights $\lambda_F=0.5, \lambda_R=0.5$. You can run this experiment by running:    
    
    \texttt{python main.py --factorization\_weight 0.5 --regression\_weight 0.5 \\--logdir run/shared=True\_LF=0.5\_LR=0.5}
    
    \item Evaluate a model with \textbf{separate} representations and task weights $\lambda_F=0.5, \lambda_R=0.5$. You can run this experiment by running:    
    
    \texttt{python main.py --no\_shared\_embeddings --factorization\_weight 0.5 \\ --regression\_weight 0.5 --logdir run/shared=False\_LF=0.5\_LR=0.5}
    
     \item Evaluate a model with \textbf{separate} representations and task weights $\lambda_F=0.99, \lambda_R=0.01$. You can run this experiment by running:    
    
    \texttt{python main.py --no\_shared\_embeddings --factorization\_weight 0.99 \\ --regression\_weight 0.01 --logdir run/shared=False\_LF=0.99\_LR=0.01}
    
\end{enumerate}

\noindent\textbf{Your plots go here}:

\begin{enumerate}
    \item Shared representations and task weights $\lambda_F=0.99, \lambda_R=0.01$

    \includegraphics[scale=1.5]{report/1_train}
    \includegraphics[scale=2.0]{report/1_eval}

    \item Shared representations and task weights $\lambda_F=0.5, \lambda_R=0.5$

    \includegraphics[scale=1.5]{report/2_train}
    \includegraphics[scale=2.0]{report/2_eval}

    \item \textbf{Separate} representations and task weights $\lambda_F=0.5, \lambda_R=0.5$

    \includegraphics[scale=1.5]{report/3_train}
    \includegraphics[scale=2.0]{report/3_eval}

    \item \textbf{Separate} representations and task weights  $\lambda_F=0.99, \lambda_R=0.01$

    \includegraphics[scale=1.5]{report/4_train}
    \includegraphics[scale=2.0]{report/4_eval}

\end{enumerate}
For each experiment include a screenshot of Tensorboard graphs for the training and test set losses in your write up. Answer the following questions:

\begin{enumerate}
    \item Consider the case with $\lambda_F=0.99$ and $\lambda_R=0.01$. Based on the train/test loss curves, does parameter sharing outperform having separate models? 
    
    \item Now consider the case with $\lambda_F=0.5$ and $\lambda_R=0.5$.  Based on the train/test loss curves, does parameter sharing outperform having separate models? 
    
    \item In the \textbf{shared model setting} compare results for $\lambda_F=0.99$ and $\lambda_R=0.01$ and $\lambda_F=0.5$ and $\lambda_R=0.5$, can you explain the difference in performance?
\end{enumerate}

\noindent\textbf{Your answers go here}:

\begin{enumerate}
    \item Considering the case with $\lambda_F=0.99$ and $\lambda_R=0.01$: Based on evaluation metrics,parameter sharing outperform having separate model.

    \item Considering the case with $\lambda_F=0.5$ and $\lambda_R=0.5$:  Based on the train/test loss curves, parameter sharing does not outperform having separate models.

    \item In the \textbf{shared model setting} $\lambda_F=0.99$ and $\lambda_R=0.01$ case outperforms $\lambda_F=0.5$ and $\lambda_R=0.5$ case. In fact $\lambda_F=0.5$ and $\lambda_R=0.5$ case performs very poorly. This suggests regression problem is not suitable for sharing while factorization problem seems to be suitable for parameter sharing.

\end{enumerate}

\newpage
\bibliography{references}
\bibliographystyle{unsrt}

\end{document}
